import os
import torch
import cv2
import numpy as np
from model import HeatmapUNet  # æˆ– HeatmapNet
from config import *
from dataset import preprocess_image
import matplotlib.pyplot as plt
import scipy.ndimage

class KalmanPoint:
    def __init__(self):
        self.state = np.zeros(4)  # [x, y, vx, vy]
        self.P = np.eye(4) * 1000  # åˆå§‹åæ–¹å·®
        self.F = np.eye(4)  # çŠ¶æ€è½¬ç§»çŸ©é˜µ
        self.F[0, 2] = 1
        self.F[1, 3] = 1
        self.H = np.array([[1, 0, 0, 0],
                           [0, 1, 0, 0]])  # è§‚æµ‹çŸ©é˜µ
        self.R = np.eye(2) * 25  # æµ‹é‡å™ªå£°
        self.Q = np.eye(4) * 0.01  # è¿‡ç¨‹å™ªå£°

    def predict(self):
        self.state = self.F @ self.state
        self.P = self.F @ self.P @ self.F.T + self.Q

    def update(self, z):
        y = z - (self.H @ self.state)
        S = self.H @ self.P @ self.H.T + self.R
        K = self.P @ self.H.T @ np.linalg.inv(S)
        self.state += K @ y
        self.P = (np.eye(4) - K @ self.H) @ self.P

    def get_pos(self):
        return int(self.state[0]), int(self.state[1])

    def set_pos(self, x, y):
        self.state[0] = x
        self.state[1] = y
        self.state[2] = 0
        self.state[3] = 0

class KalmanSmoother:
    def __init__(self):
        self.trackers = []

    def update(self, keypoints):
        if len(self.trackers) != len(keypoints):
            self.trackers = [KalmanPoint() for _ in keypoints]
            for tracker, (x, y) in zip(self.trackers, keypoints):
                tracker.set_pos(x, y)

        smoothed = []
        for tracker, (x, y) in zip(self.trackers, keypoints):
            tracker.predict()
            tracker.update(np.array([x, y]))
            smoothed.append(tracker.get_pos())

        return smoothed

# é€šé“åŒ¹é…--è®© pred å’Œ heatmap çš„é€šé“æ•°å¯¹é½
def match_channels(pred, heatmap):
    _, c_pred, h, w = pred.shape
    _, c_gt, _, _ = heatmap.shape
    if c_pred == c_gt:
        return pred
    elif c_pred > c_gt:
        return pred[:, :c_gt, :, :]
    else:
        pad = torch.zeros((1, c_gt - c_pred, h, w), device=pred.device, dtype=pred.dtype)
        return torch.cat([pred, pad], dim=1)

# ä»çƒ­å›¾ä¸­æå–å…³é”®ç‚¹åæ ‡
def extract_peak_coords(heatmap_tensor, orig_size=None, threshold=0.15, nms_radius=5, merge_distance=15):
    heatmap_np = heatmap_tensor.squeeze(0).detach().cpu().numpy()
    coords = []

    for hm in heatmap_np:
        neighborhood = (nms_radius * 2) + 1
        local_max = (hm == scipy.ndimage.maximum_filter(hm, size=neighborhood))
        mask = (hm > threshold) & local_max

        ys, xs = np.where(mask)
        keypoints = [(x, y, hm[y, x]) for x, y in zip(xs, ys)]

        keypoints.sort(key=lambda k: k[2], reverse=True)

        selected = []
        for x, y, score in keypoints:
            too_close = False
            for sel_x, sel_y in selected:
                if np.hypot(x - sel_x, y - sel_y) < merge_distance:
                    too_close = True
                    break
            if not too_close:
                selected.append((x, y))

        for (x, y) in selected:
            if orig_size is not None:
                scale_x = orig_size[1] / hm.shape[1]
                scale_y = orig_size[0] / hm.shape[0]
                x = int(x * scale_x)
                y = int(y * scale_y)
            coords.append((x, y))

    return coords

# å…³é”®ç‚¹å¹³æ»‘å™¨
# class KeypointSmoother:
#     def __init__(self, window_size=5):
#         self.window_size = window_size
#         self.buffers = None  # æ¯ä¸ªç‚¹æœ‰è‡ªå·±çš„å°bufferåˆ—è¡¨
#
#     def update(self, keypoints):
#         keypoints = np.array(keypoints)
#         if self.buffers is None:
#             # ç¬¬ä¸€æ¬¡åˆå§‹åŒ–
#             self.buffers = [[] for _ in range(len(keypoints))]
#
#         if len(keypoints) != len(self.buffers):
#             # æ•°é‡å¯¹ä¸ä¸Šï¼Œé‡æ–°åˆå§‹åŒ–
#             self.buffers = [[] for _ in range(len(keypoints))]
#
#         for i, (x, y) in enumerate(keypoints):
#             self.buffers[i].append((x, y))
#             if len(self.buffers[i]) > self.window_size:
#                 self.buffers[i].pop(0)
#
#         return self.get_smoothed()
#
#     def get_smoothed(self):
#         smoothed = []
#         for buffer in self.buffers:
#             if buffer:
#                 avg_x = np.mean([p[0] for p in buffer])
#                 avg_y = np.mean([p[1] for p in buffer])
#                 smoothed.append((int(avg_x), int(avg_y)))
#         return smoothed

# æ ‡æ³¨å…³é”®ç‚¹
def visualize_keypoints(img, keypoints):
    for x, y in keypoints:
        cv2.circle(img, (x, y), 5, (0, 255, 0), -1)
    return img

def val_video(video_path):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    model = HeatmapUNet(num_keypoints=8).to(device)
    best_model_path = "checkpoints/best_model.pt"
    assert os.path.exists(best_model_path), "æ²¡æœ‰æ‰¾åˆ°æœ€ä½³æ¨¡å‹ï¼Œè¯·å…ˆè®­ç»ƒä¸€éã€‚"
    model.load_state_dict(torch.load(best_model_path, map_location=device))
    model.eval()

    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print("âŒ æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶")
        return

    smoother = KalmanSmoother()  # åˆå§‹åŒ–å¹³æ»‘å™¨

    while True:
        ret, frame = cap.read()
        if not ret:
            print("ğŸšª è§†é¢‘ç»“æŸï¼Œä¼˜é›…é€€å‡ºã€‚")
            break

        orig_h, orig_w = frame.shape[:2]
        img_input = preprocess_image(frame)
        img_tensor = torch.from_numpy(img_input).unsqueeze(0).to(device)

        with torch.no_grad():
            pred_heatmap = model(img_tensor)

        keypoints = extract_peak_coords(pred_heatmap, orig_size=(orig_h, orig_w))
        keypoints = smoother.update(keypoints)  # åŠ å…¥å¹³æ»‘ï¼

        vis_frame = visualize_keypoints(frame.copy(), keypoints)

        cv2.imshow("Keypoint Detection", vis_frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            print("ğŸ‘‹ æ‰‹åŠ¨é€€å‡ºã€‚")
            break

    cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    video_path = "/home/wangzhe/ICRA2025/MY/demo/left.mp4"
    val_video(video_path)
